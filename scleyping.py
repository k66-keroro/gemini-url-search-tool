import tkinter as tk
from tkinter import ttk, scrolledtext, messagebox
import sqlite3
import requests
from bs4 import BeautifulSoup
import re
import threading
from urllib.parse import urljoin, quote

DB_FILE = "fuji_parts_test.db"

class PartsScraper:
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
    
    def search_fuji_electric(self, part_number):
        """å¯Œå£«é›»æ©Ÿã®ã‚µã‚¤ãƒˆã‹ã‚‰éƒ¨å“æƒ…å ±ã‚’æ¤œç´¢"""
        search_urls = []
        try:
            # å¯Œå£«é›»æ©Ÿã®æ¤œç´¢URLï¼ˆä¾‹ï¼‰
            base_url = "https://www.fujielectric.co.jp"
            search_urls = [
                f"{base_url}/products/search?q={quote(part_number)}",
                f"{base_url}/products/electronic_components/search?keyword={quote(part_number)}",
                f"{base_url}/search?keyword={quote(part_number)}",
                f"https://felib.fujielectric.co.jp/download/search.htm?keyword={quote(part_number)}"
            ]
            
            for url in search_urls:
                print(f"ğŸ” å¯Œå£«é›»æ©ŸURL: {url}")
                try:
                    response = self.session.get(url, timeout=10)
                    print(f"ğŸ“Š ãƒ¬ã‚¹ãƒãƒ³ã‚¹: {response.status_code}")
                    if response.status_code == 200:
                        result = self.parse_fuji_page(response.text, part_number)
                        if result:
                            result['search_urls'] = search_urls
                            return result
                except Exception as e:
                    print(f"âŒ URLå¤±æ•— {url}: {e}")
                    continue
                    
        except Exception as e:
            print(f"å¯Œå£«é›»æ©Ÿæ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
        
        return {'search_urls': search_urls, 'error': 'ã™ã¹ã¦ã®URLã§404ã¾ãŸã¯ã‚¨ãƒ©ãƒ¼'}
    
    def search_hoei_denki(self, part_number):
        """å®æ°¸é›»æ©Ÿã®ã‚µã‚¤ãƒˆã‹ã‚‰éƒ¨å“æƒ…å ±ã‚’æ¤œç´¢"""
        search_urls = []
        try:
            # å®æ°¸é›»æ©Ÿã®æ­£ã—ã„URLã‚’èª¿æŸ»
            search_urls = [
                f"https://www.hoei.co.jp/",  # ãƒˆãƒƒãƒ—ãƒšãƒ¼ã‚¸ã‹ã‚‰æ‰‹å‹•ç¢ºèªç”¨
                f"https://hoei.co.jp/",     # wwwãªã—ç‰ˆ
                f"https://www.hoei-denki.co.jp/search?q={quote(part_number)}",  # æ¨æ¸¬URL
                f"https://hoei-denki.co.jp/products/{quote(part_number)}",      # æ¨æ¸¬URL
            ]
            
            for url in search_urls:
                print(f"ğŸ” å®æ°¸é›»æ©ŸURL: {url}")
                try:
                    response = self.session.get(url, timeout=10)
                    print(f"ğŸ“Š ãƒ¬ã‚¹ãƒãƒ³ã‚¹: {response.status_code}")
                    if response.status_code == 200:
                        result = self.parse_hoei_page(response.text, part_number)
                        if result:
                            result['search_urls'] = search_urls
                            return result
                except Exception as e:
                    print(f"âŒ URLå¤±æ•— {url}: {str(e)[:100]}...")
                    continue
                    
        except Exception as e:
            print(f"å®æ°¸é›»æ©Ÿæ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
        
        return {'search_urls': search_urls, 'error': 'ã™ã¹ã¦ã®URLã§404ã¾ãŸã¯ã‚¨ãƒ©ãƒ¼'}
    
    def parse_fuji_page(self, html_content, part_number):
        """å¯Œå£«é›»æ©Ÿã®ãƒšãƒ¼ã‚¸ã‚’è§£æï¼ˆæ”¹è‰¯ç‰ˆï¼‰"""
        soup = BeautifulSoup(html_content, 'html.parser')
        
        print(f"ğŸ“„ HTMLã‚µã‚¤ã‚º: {len(html_content)} æ–‡å­—")
        
        # ã‚ˆã‚Šç²¾å¯†ãªä»•æ§˜æƒ…å ±ã®æŠ½å‡º
        specs = {}
        
        # 1. ãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰æŠ½å‡º
        for table in soup.find_all('table'):
            for row in table.find_all('tr'):
                cells = row.find_all(['td', 'th'])
                if len(cells) >= 2:
                    header = cells[0].get_text().strip()
                    value = cells[1].get_text().strip()
                    
                    # é›»åœ§é–¢é€£
                    if any(keyword in header.lower() for keyword in ['é›»åœ§', 'voltage', 'å®šæ ¼é›»åœ§']):
                        if self._is_valid_voltage(value):
                            specs['voltage'] = value
                    
                    # é›»æµé–¢é€£
                    elif any(keyword in header.lower() for keyword in ['é›»æµ', 'current', 'å®šæ ¼é›»æµ']):
                        if self._is_valid_current(value):
                            specs['current_rating'] = value
                    
                    # å¯¸æ³•é–¢é€£
                    elif any(keyword in header.lower() for keyword in ['å¯¸æ³•', 'dimension', 'ã‚µã‚¤ã‚º']):
                        specs['dimensions'] = value
                    
                    # é‡é‡é–¢é€£
                    elif any(keyword in header.lower() for keyword in ['é‡é‡', 'weight', 'è³ªé‡']):
                        if self._is_valid_weight(value):
                            specs['weight'] = value
        
        # 2. æ¤œç´¢çµæœä¸€è¦§ã‹ã‚‰è£½å“ãƒªãƒ³ã‚¯ã‚’æ¢ã™
        product_links = []
        for link in soup.find_all('a', href=True):
            href = link['href']
            text = link.get_text().strip()
            if part_number.upper() in text.upper() or part_number.lower() in href.lower():
                product_links.append(urljoin('https://www.fujielectric.co.jp', href))
        
        if product_links:
            specs['product_links'] = product_links[:3]  # æœ€å¤§3å€‹ã¾ã§
            print(f"ğŸ”— è£½å“ãƒªãƒ³ã‚¯ç™ºè¦‹: {len(product_links)}å€‹")
        
        # 3. ãƒ‡ãƒ¼ã‚¿ã‚·ãƒ¼ãƒˆãƒªãƒ³ã‚¯
        datasheet_link = self.find_datasheet_link(soup)
        if datasheet_link:
            specs['datasheet'] = urljoin('https://www.fujielectric.co.jp', datasheet_link)
        
        print(f"ğŸ¯ æŠ½å‡ºã—ãŸä»•æ§˜: {list(specs.keys())}")
        return specs if specs else None
    
    def _is_valid_voltage(self, value):
        """é›»åœ§å€¤ãŒæœ‰åŠ¹ã‹ãƒã‚§ãƒƒã‚¯"""
        # -127Vã®ã‚ˆã†ãªæ˜ã‚‰ã‹ã«é–“é•ã£ãŸå€¤ã‚’é™¤å¤–
        if re.search(r'-?\d+(\.\d+)?\s*V', value):
            voltage_match = re.search(r'(-?\d+(?:\.\d+)?)', value)
            if voltage_match:
                voltage = float(voltage_match.group(1))
                return -1000 < voltage < 1000  # ç¾å®Ÿçš„ãªç¯„å›²
        return False
    
    def _is_valid_current(self, value):
        """é›»æµå€¤ãŒæœ‰åŠ¹ã‹ãƒã‚§ãƒƒã‚¯"""
        return re.search(r'\d+(\.\d+)?\s*[mM]?A', value) is not None
    
    def _is_valid_weight(self, value):
        """é‡é‡å€¤ãŒæœ‰åŠ¹ã‹ãƒã‚§ãƒƒã‚¯"""
        return re.search(r'\d+(\.\d+)?\s*[gk]', value) is not None
    
    def parse_hoei_page(self, html_content, part_number):
        """å®æ°¸é›»æ©Ÿã®ãƒšãƒ¼ã‚¸ã‚’è§£æ"""
        soup = BeautifulSoup(html_content, 'html.parser')
        
        specs = {
            'price': self.extract_spec(soup, ['ä¾¡æ ¼', 'price', 'å††', 'Â¥']),
            'stock': self.extract_spec(soup, ['åœ¨åº«', 'stock', 'å€‹']),
            'delivery': self.extract_spec(soup, ['ç´æœŸ', 'delivery', 'æ—¥'])
        }
        
        return specs
    
    def extract_spec(self, soup, keywords):
        """ä»•æ§˜æƒ…å ±ã‚’æŠ½å‡º"""
        for keyword in keywords:
            # ãƒ†ãƒ¼ãƒ–ãƒ«å†…ã‚’æ¤œç´¢
            for table in soup.find_all('table'):
                for row in table.find_all('tr'):
                    cells = row.find_all(['td', 'th'])
                    for i, cell in enumerate(cells):
                        if keyword.lower() in cell.get_text().lower():
                            if i + 1 < len(cells):
                                return cells[i + 1].get_text().strip()
            
            # divã€spanç­‰ã‚’æ¤œç´¢
            for tag in soup.find_all(['div', 'span', 'p']):
                text = tag.get_text()
                if keyword.lower() in text.lower():
                    # æ•°å€¤ã¨å˜ä½ã‚’æŠ½å‡º
                    match = re.search(rf'{keyword}[:\s]*([0-9.,~-]+\s*[A-Za-zâ„ƒ%]*)', text, re.IGNORECASE)
                    if match:
                        return match.group(1).strip()
        
        return None
    
    def find_datasheet_link(self, soup):
        """ãƒ‡ãƒ¼ã‚¿ã‚·ãƒ¼ãƒˆã®ãƒªãƒ³ã‚¯ã‚’æ¤œç´¢"""
        for link in soup.find_all('a', href=True):
            href = link['href']
            text = link.get_text().lower()
            if any(keyword in text for keyword in ['datasheet', 'ãƒ‡ãƒ¼ã‚¿ã‚·ãƒ¼ãƒˆ', 'pdf', 'ä»•æ§˜æ›¸']):
                return href
            if href.lower().endswith('.pdf'):
                return href
        return None

class PartsSearchApp:
    def __init__(self, root):
        self.root = root
        self.scraper = PartsScraper()
        self.setup_database()
        self.setup_gui()
    
    def setup_database(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’åˆæœŸåŒ–"""
        conn = sqlite3.connect(DB_FILE)
        cursor = conn.cursor()
        
        # æ—¢å­˜ãƒ†ãƒ¼ãƒ–ãƒ«ã®æ§‹é€ ã‚’ç¢ºèª
        cursor.execute("PRAGMA table_info(part_specifications)")
        existing_columns = [column[1] for column in cursor.fetchall()]
        
        if not existing_columns:
            # ãƒ†ãƒ¼ãƒ–ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯æ–°è¦ä½œæˆ
            cursor.execute("""
                CREATE TABLE part_specifications (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    part_number TEXT UNIQUE,
                    voltage TEXT,
                    absorption_type TEXT,
                    capacitance TEXT,
                    resistance TEXT,
                    current_rating TEXT,
                    temperature_range TEXT,
                    dimensions TEXT,
                    weight TEXT,
                    price TEXT,
                    stock TEXT,
                    delivery TEXT,
                    datasheet_url TEXT,
                    search_urls TEXT,
                    remarks TEXT,
                    last_updated DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            """)
            print("æ–°ã—ã„ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆã—ã¾ã—ãŸ")
        else:
            print(f"æ—¢å­˜ã®ã‚«ãƒ©ãƒ : {existing_columns}")
            
            # å¿…è¦ãªã‚«ãƒ©ãƒ ã‚’è¿½åŠ 
            new_columns = {
                'current_rating': 'TEXT',
                'temperature_range': 'TEXT', 
                'dimensions': 'TEXT',
                'weight': 'TEXT',
                'price': 'TEXT',
                'stock': 'TEXT',
                'delivery': 'TEXT',
                'datasheet_url': 'TEXT',
                'search_urls': 'TEXT',
                'last_updated': 'DATETIME'
            }
            
            for col_name, col_type in new_columns.items():
                if col_name not in existing_columns:
                    try:
                        cursor.execute(f"ALTER TABLE part_specifications ADD COLUMN {col_name} {col_type}")
                        print(f"ã‚«ãƒ©ãƒ  {col_name} ã‚’è¿½åŠ ã—ã¾ã—ãŸ")
                    except sqlite3.OperationalError as e:
                        print(f"ã‚«ãƒ©ãƒ  {col_name} è¿½åŠ å¤±æ•—: {e}")
        
        conn.commit()
        conn.close()
    
    def setup_gui(self):
        """GUIã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
        self.root.title("éƒ¨å“ä»•æ§˜æ¤œç´¢ãƒ„ãƒ¼ãƒ«ï¼ˆã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å¯¾å¿œï¼‰")
        self.root.geometry("900x700")
        
        # å…¥åŠ›ãƒ•ãƒ¬ãƒ¼ãƒ 
        input_frame = ttk.Frame(self.root, padding="10")
        input_frame.pack(fill=tk.X)
        
        ttk.Label(input_frame, text="å“ç•ªã‚’å…¥åŠ›:").grid(row=0, column=0, sticky=tk.W)
        self.part_entry = ttk.Entry(input_frame, width=40)
        self.part_entry.grid(row=0, column=1, padx=5)
        self.part_entry.bind('<Return>', lambda e: self.search_part())
        
        # ãƒœã‚¿ãƒ³ãƒ•ãƒ¬ãƒ¼ãƒ 
        button_frame = ttk.Frame(input_frame)
        button_frame.grid(row=0, column=2, padx=5)
        
        self.search_button = ttk.Button(button_frame, text="DBæ¤œç´¢", command=self.search_part)
        self.search_button.pack(side=tk.LEFT, padx=2)
        
        self.scrape_button = ttk.Button(button_frame, text="Webæ¤œç´¢", command=self.scrape_part)
        self.scrape_button.pack(side=tk.LEFT, padx=2)
        
        self.update_button = ttk.Button(button_frame, text="DBæ›´æ–°", command=self.update_database)
        self.update_button.pack(side=tk.LEFT, padx=2)
        
        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼
        self.progress = ttk.Progressbar(self.root, mode='indeterminate')
        self.progress.pack(fill=tk.X, padx=10, pady=5)
        
        # çµæœè¡¨ç¤ºãƒ•ãƒ¬ãƒ¼ãƒ 
        result_frame = ttk.Frame(self.root, padding="10")
        result_frame.pack(fill=tk.BOTH, expand=True)
        
        self.result_text = scrolledtext.ScrolledText(result_frame, wrap=tk.WORD, width=100, height=30)
        self.result_text.pack(fill=tk.BOTH, expand=True)
        
        # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒãƒ¼
        self.status_var = tk.StringVar()
        self.status_var.set("æº–å‚™å®Œäº†")
        status_bar = ttk.Label(self.root, textvariable=self.status_var, relief=tk.SUNKEN)
        status_bar.pack(fill=tk.X, side=tk.BOTTOM)
    
    def search_part(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰éƒ¨å“ã‚’æ¤œç´¢"""
        part_number = self.part_entry.get().strip()
        if not part_number:
            messagebox.showwarning("å…¥åŠ›ã‚¨ãƒ©ãƒ¼", "å“ç•ªã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            return
        
        try:
            conn = sqlite3.connect(DB_FILE)
            cursor = conn.cursor()
            cursor.execute("""
                SELECT * FROM part_specifications WHERE part_number = ?
            """, (part_number,))
            result = cursor.fetchone()
            conn.close()
            
            self.result_text.delete(1.0, tk.END)
            if result:
                self.display_result(result, "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹")
            else:
                self.result_text.insert(tk.END, f"å“ç•ªã€Œ{part_number}ã€ã®æƒ…å ±ã¯ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ã‚ã‚Šã¾ã›ã‚“ã€‚\nWebæ¤œç´¢ã‚’è©¦ã—ã¦ãã ã•ã„ã€‚")
                
        except Exception as e:
            messagebox.showerror("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼", f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ:\n{e}")
    
    def scrape_part(self):
        """Webã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã§éƒ¨å“æƒ…å ±ã‚’æ¤œç´¢"""
        part_number = self.part_entry.get().strip()
        if not part_number:
            messagebox.showwarning("å…¥åŠ›ã‚¨ãƒ©ãƒ¼", "å“ç•ªã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            return
        
        # ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§å®Ÿè¡Œ
        threading.Thread(target=self._scrape_thread, args=(part_number,), daemon=True).start()
    
    def _scrape_thread(self, part_number):
        """ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚’ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§å®Ÿè¡Œ"""
        self.root.after(0, lambda: self.progress.start())
        self.root.after(0, lambda: self.status_var.set(f"æ¤œç´¢ä¸­: {part_number}"))
        
        try:
            # å¯Œå£«é›»æ©Ÿã¨å®æ°¸é›»æ©Ÿã‹ã‚‰æ¤œç´¢
            fuji_data = self.scraper.search_fuji_electric(part_number)
            hoei_data = self.scraper.search_hoei_denki(part_number)
            
            # çµæœã‚’ãƒãƒ¼ã‚¸
            merged_data = {}
            if fuji_data:
                merged_data.update(fuji_data)
            if hoei_data:
                merged_data.update(hoei_data)
            
            self.root.after(0, lambda: self._display_scrape_result(part_number, merged_data))
            
        except Exception as e:
            self.root.after(0, lambda: messagebox.showerror("ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼", f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ:\n{e}"))
        
        finally:
            self.root.after(0, lambda: self.progress.stop())
            self.root.after(0, lambda: self.status_var.set("æº–å‚™å®Œäº†"))
    
    def _display_scrape_result(self, part_number, data):
        """ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°çµæœã‚’è¡¨ç¤º"""
        self.result_text.delete(1.0, tk.END)
        
        # æ¤œç´¢URLä¸€è¦§ã‚’è¡¨ç¤º
        output = f"ğŸŒ Webæ¤œç´¢çµæœ: {part_number}\n"
        output += "=" * 50 + "\n"
        
        # æ¤œç´¢ã—ãŸURLã‚’è¡¨ç¤º
        if data.get('search_urls'):
            output += "ğŸ”— æ¤œç´¢URL:\n"
            for i, url in enumerate(data['search_urls'], 1):
                output += f"   {i}. {url}\n"
            output += "\n"
        
        if not data or all(v is None or v == '' for k, v in data.items() if k not in ['search_urls', 'error']):
            output += f"âŒ å“ç•ªã€Œ{part_number}ã€ã®æƒ…å ±ãŒWebã§è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\n\n"
            output += "ğŸ“‹ å¯èƒ½ãªåŸå› :\n"
            output += "ãƒ»URLãŒå¤‰æ›´ã•ã‚Œã¦ã„ã‚‹\n"
            output += "ãƒ»èªè¨¼ãŒå¿…è¦ãªãƒšãƒ¼ã‚¸\n"
            output += "ãƒ»éƒ¨å“ç•ªå·ã®è¡¨è¨˜é•ã„\n"
            output += "ãƒ»JavaScriptã«ã‚ˆã‚‹å‹•çš„ç”Ÿæˆ\n"
            
            if data.get('error'):
                output += f"ãƒ»ã‚¨ãƒ©ãƒ¼è©³ç´°: {data['error']}\n"
        else:
            output += "âœ… å–å¾—ã—ãŸä»•æ§˜æƒ…å ±:\n"
            
            if data.get('voltage'):
                output += f"ğŸ”Œ é›»åœ§: {data['voltage']}\n"
            if data.get('current_rating'):
                output += f"âš¡ é›»æµå®šæ ¼: {data['current_rating']}\n"
            if data.get('temperature_range'):
                output += f"ğŸŒ¡ï¸ å‹•ä½œæ¸©åº¦: {data['temperature_range']}\n"
            if data.get('dimensions'):
                output += f"ğŸ“ å¯¸æ³•: {data['dimensions']}\n"
            if data.get('weight'):
                output += f"âš–ï¸ é‡é‡: {data['weight']}\n"
            if data.get('price'):
                output += f"ğŸ’° ä¾¡æ ¼: {data['price']}\n"
            if data.get('stock'):
                output += f"ğŸ“¦ åœ¨åº«: {data['stock']}\n"
            if data.get('delivery'):
                output += f"ğŸšš ç´æœŸ: {data['delivery']}\n"
            if data.get('datasheet'):
                output += f"ğŸ“„ ãƒ‡ãƒ¼ã‚¿ã‚·ãƒ¼ãƒˆ: {data['datasheet']}\n"
            
            output += "\nâ€» ã“ã®æƒ…å ±ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ã™ã‚‹å ´åˆã¯ã€ŒDBæ›´æ–°ã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚"
        
        self.result_text.insert(tk.END, output)
        self.current_scrape_data = {part_number: data}  # æ›´æ–°ç”¨ã«ä¿å­˜
    
    def update_database(self):
        """ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°çµæœã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜"""
        if not hasattr(self, 'current_scrape_data'):
            messagebox.showwarning("æ›´æ–°ã‚¨ãƒ©ãƒ¼", "æ›´æ–°ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚å…ˆã«Webæ¤œç´¢ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
            return
        
        try:
            conn = sqlite3.connect(DB_FILE)
            cursor = conn.cursor()
            
            # ãƒ†ãƒ¼ãƒ–ãƒ«æ§‹é€ ã‚’ç¢ºèª
            cursor.execute("PRAGMA table_info(part_specifications)")
            columns = [column[1] for column in cursor.fetchall()]
            print(f"ãƒ†ãƒ¼ãƒ–ãƒ«ã®ã‚«ãƒ©ãƒ : {columns}")
            
            for part_number, data in self.current_scrape_data.items():
                # æ¤œç´¢URLã‚’JSONæ–‡å­—åˆ—ã¨ã—ã¦ä¿å­˜
                search_urls_str = str(data.get('search_urls', []))
                
                if 'last_updated' in columns:
                    # last_updatedã‚«ãƒ©ãƒ ãŒã‚ã‚‹å ´åˆ
                    cursor.execute("""
                        INSERT OR REPLACE INTO part_specifications 
                        (part_number, voltage, current_rating, temperature_range, dimensions, weight, 
                         price, stock, delivery, datasheet_url, search_urls, last_updated)
                        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, CURRENT_TIMESTAMP)
                    """, (
                        part_number,
                        data.get('voltage'),
                        data.get('current_rating'),
                        data.get('temperature_range'),
                        data.get('dimensions'),
                        data.get('weight'),
                        data.get('price'),
                        data.get('stock'),
                        data.get('delivery'),
                        data.get('datasheet'),
                        search_urls_str
                    ))
                else:
                    # last_updatedã‚«ãƒ©ãƒ ãŒãªã„å ´åˆ
                    cursor.execute("""
                        INSERT OR REPLACE INTO part_specifications 
                        (part_number, voltage, current_rating, temperature_range, dimensions, weight, 
                         price, stock, delivery, datasheet_url, search_urls)
                        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                    """, (
                        part_number,
                        data.get('voltage'),
                        data.get('current_rating'),
                        data.get('temperature_range'),
                        data.get('dimensions'),
                        data.get('weight'),
                        data.get('price'),
                        data.get('stock'),
                        data.get('delivery'),
                        data.get('datasheet'),
                        search_urls_str
                    ))
            
            conn.commit()
            conn.close()
            
            messagebox.showinfo("æ›´æ–°å®Œäº†", f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒæ›´æ–°ã•ã‚Œã¾ã—ãŸã€‚\nå“ç•ª: {', '.join(self.current_scrape_data.keys())}")
            del self.current_scrape_data  # ä¿å­˜å¾Œã«å‰Šé™¤
            
        except Exception as e:
            messagebox.showerror("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼", f"æ›´æ–°ã«å¤±æ•—ã—ã¾ã—ãŸ:\n{e}")
            print(f"DBæ›´æ–°ã‚¨ãƒ©ãƒ¼è©³ç´°: {e}")  # ãƒ‡ãƒãƒƒã‚°ç”¨
    
    def display_result(self, result, source):
        """æ¤œç´¢çµæœã‚’è¡¨ç¤º"""
        if not result:
            return
            
        output = f"ğŸ” {source}æ¤œç´¢çµæœ\n"
        output += "=" * 50 + "\n"
        output += f"ğŸ”§ å“ç•ª: {result[1]}\n"
        
        if result[2]:  # voltage
            output += f"ğŸ”Œ é›»åœ§: {result[2]}\n"
        if result[3]:  # current
            output += f"âš¡ é›»æµ: {result[3]}\n"
        if result[4]:  # temperature
            output += f"ğŸŒ¡ï¸ å‹•ä½œæ¸©åº¦: {result[4]}\n"
        if result[5]:  # dimensions
            output += f"ğŸ“ å¯¸æ³•: {result[5]}\n"
        if result[6]:  # weight
            output += f"âš–ï¸ é‡é‡: {result[6]}\n"
        if result[7]:  # price
            output += f"ğŸ’° ä¾¡æ ¼: {result[7]}\n"
        if result[8]:  # stock
            output += f"ğŸ“¦ åœ¨åº«: {result[8]}\n"
        if result[9]:  # delivery
            output += f"ğŸšš ç´æœŸ: {result[9]}\n"
        if result[10]:  # datasheet_url
            output += f"ğŸ“„ ãƒ‡ãƒ¼ã‚¿ã‚·ãƒ¼ãƒˆ: {result[10]}\n"
        if result[11]:  # remarks
            output += f"ğŸ“ å‚™è€ƒ: {result[11]}\n"
        if result[12]:  # last_updated
            output += f"ğŸ• æœ€çµ‚æ›´æ–°: {result[12]}\n"
        
        self.result_text.insert(tk.END, output)

if __name__ == "__main__":
    root = tk.Tk()
    app = PartsSearchApp(root)
    root.mainloop()