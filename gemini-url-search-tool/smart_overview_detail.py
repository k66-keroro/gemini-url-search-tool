#!/usr/bin/env python3
"""
Smart Overview & Detail Tool - æ¦‚è¦ä¸€è¦§â†’è©³ç´°è¡¨ç¤ºã®ç†æƒ³çš„ãªUI
"""

import streamlit as st
import os
import requests
from dotenv import load_dotenv
from bs4 import BeautifulSoup
import google.generativeai as genai
import time
from urllib.parse import quote_plus, urlparse
import re

# Load environment variables
load_dotenv()

def search_with_multiple_sources(query, num_results=10):
    """è¤‡æ•°ã®ã‚½ãƒ¼ã‚¹ã‹ã‚‰æ¤œç´¢çµæœã‚’å–å¾—"""
    results = []
    
    # Wikipediaæ¤œç´¢
    try:
        wiki_url = f"https://en.wikipedia.org/w/api.php?action=opensearch&search={quote_plus(query)}&limit=3&format=json"
        response = requests.get(wiki_url, timeout=10)
        data = response.json()
        
        if len(data) >= 4:
            titles = data[1]
            descriptions = data[2]
            urls = data[3]
            
            for i in range(min(len(titles), 3)):
                results.append({
                    'title': f"{titles[i]} - Wikipedia",
                    'url': urls[i],
                    'description': descriptions[i] if i < len(descriptions) else "Wikipedia article",
                    'source': 'Wikipedia',
                    'confidence': 0.9
                })
    except:
        pass
    
    # GitHubæ¤œç´¢
    try:
        github_url = f"https://api.github.com/search/repositories?q={quote_plus(query)}&sort=stars&order=desc&per_page=3"
        response = requests.get(github_url, timeout=10)
        data = response.json()
        
        if 'items' in data:
            for repo in data['items'][:3]:
                results.append({
                    'title': f"{repo['name']} - GitHub",
                    'url': repo['html_url'],
                    'description': repo.get('description', 'GitHub repository'),
                    'source': 'GitHub',
                    'confidence': 0.8
                })
    except:
        pass
    
    # æ‰‹å‹•ã§é«˜å“è³ªã‚µã‚¤ãƒˆã‚’è¿½åŠ 
    manual_sites = {
        'python': [
            {'title': 'Python.org - Official Site', 'url': 'https://www.python.org/', 'description': 'Official Python programming language website', 'confidence': 1.0},
            {'title': 'Python Documentation', 'url': 'https://docs.python.org/3/', 'description': 'Comprehensive Python documentation', 'confidence': 1.0},
            {'title': 'Real Python Tutorials', 'url': 'https://realpython.com/', 'description': 'High-quality Python tutorials and articles', 'confidence': 0.9},
        ],
        'machine learning': [
            {'title': 'Scikit-learn', 'url': 'https://scikit-learn.org/', 'description': 'Machine learning library for Python', 'confidence': 0.9},
            {'title': 'TensorFlow', 'url': 'https://www.tensorflow.org/', 'description': 'Open source machine learning platform', 'confidence': 0.9},
        ],
        'javascript': [
            {'title': 'MDN Web Docs - JavaScript', 'url': 'https://developer.mozilla.org/en-US/docs/Web/JavaScript', 'description': 'Comprehensive JavaScript documentation', 'confidence': 1.0},
            {'title': 'JavaScript.info', 'url': 'https://javascript.info/', 'description': 'Modern JavaScript tutorial', 'confidence': 0.9},
        ],
        'react': [
            {'title': 'React Official Docs', 'url': 'https://react.dev/', 'description': 'Official React documentation', 'confidence': 1.0},
        ]
    }
    
    query_lower = query.lower()
    for keyword, sites in manual_sites.items():
        if keyword in query_lower:
            for site in sites:
                site['source'] = 'Curated'
                results.append(site)
    
    return results[:num_results]

def generate_quick_overview(results, query, api_key):
    """å„ã‚µã‚¤ãƒˆã®ç°¡å˜ãªæ¦‚è¦ã‚’ä¸€æ‹¬ç”Ÿæˆ"""
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel('gemini-1.5-flash')
        
        results_text = "\n".join([
            f"{i+1}. {r['title']} - {r['url']} - {r['description']}"
            for i, r in enumerate(results)
        ])
        
        overview_prompt = f"""
æ¤œç´¢ã‚¯ã‚¨ãƒªã€Œ{query}ã€ã«å¯¾ã™ã‚‹ä»¥ä¸‹ã®æ¤œç´¢çµæœã«ã¤ã„ã¦ã€å„ã‚µã‚¤ãƒˆã®ç°¡æ½”ãªæ¦‚è¦ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

ã€æ¤œç´¢çµæœã€‘
{results_text}

ã€è¦æ±‚ã€‘
å„ã‚µã‚¤ãƒˆã«ã¤ã„ã¦ä»¥ä¸‹ã®å½¢å¼ã§å›ç­”ï¼š
- é–¢é€£åº¦ï¼ˆ1-5ï¼‰
- ä¸€è¡Œæ¦‚è¦ï¼ˆ30æ–‡å­—ä»¥å†…ï¼‰
- æœŸå¾…ã§ãã‚‹å†…å®¹ï¼ˆ50æ–‡å­—ä»¥å†…ï¼‰

ã€å›ç­”å½¢å¼ã€‘
1. é–¢é€£åº¦:4 | æ¦‚è¦:Pythonå…¬å¼ã‚µã‚¤ãƒˆ | å†…å®¹:è¨€èªä»•æ§˜ã€ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã€ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«
2. é–¢é€£åº¦:3 | æ¦‚è¦:GitHub Pythoné–¢é€£ | å†…å®¹:ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã€ã‚³ãƒ¼ãƒ‰ä¾‹
...

å›ç­”:
"""
        
        response = model.generate_content(overview_prompt)
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è§£æã—ã¦å„ã‚µã‚¤ãƒˆã®æƒ…å ±ã‚’æŠ½å‡º
        overviews = []
        lines = response.text.split('\n')
        
        for i, line in enumerate(lines):
            if line.strip() and ('é–¢é€£åº¦:' in line or 'relevance:' in line.lower()):
                try:
                    # é–¢é€£åº¦ã‚’æŠ½å‡º
                    relevance_match = re.search(r'é–¢é€£åº¦:(\d+)', line)
                    relevance = int(relevance_match.group(1)) if relevance_match else 3
                    
                    # æ¦‚è¦ã‚’æŠ½å‡º
                    overview_match = re.search(r'æ¦‚è¦:([^|]+)', line)
                    overview = overview_match.group(1).strip() if overview_match else "æ¦‚è¦ä¸æ˜"
                    
                    # å†…å®¹ã‚’æŠ½å‡º
                    content_match = re.search(r'å†…å®¹:(.+)', line)
                    content = content_match.group(1).strip() if content_match else "å†…å®¹ä¸æ˜"
                    
                    if i < len(results):
                        overviews.append({
                            'relevance': relevance,
                            'overview': overview,
                            'expected_content': content
                        })
                except:
                    overviews.append({
                        'relevance': 3,
                        'overview': "AIåˆ†æä¸­...",
                        'expected_content': "è©³ç´°åˆ†æãŒå¿…è¦"
                    })
        
        # çµæœæ•°ãŒè¶³ã‚Šãªã„å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã§åŸ‹ã‚ã‚‹
        while len(overviews) < len(results):
            overviews.append({
                'relevance': 3,
                'overview': "åˆ†æä¸­...",
                'expected_content': "è©³ç´°åˆ†æãŒå¿…è¦"
            })
        
        return overviews
        
    except Exception as e:
        # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¿”ã™
        return [{
            'relevance': 3,
            'overview': "åˆ†æä¸­...",
            'expected_content': "è©³ç´°åˆ†æãŒå¿…è¦"
        } for _ in results]

def fetch_and_analyze_detailed(url, query, api_key):
    """è©³ç´°åˆ†æã‚’å®Ÿè¡Œ"""
    try:
        # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å–å¾—
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        
        response = requests.get(url, headers=headers, timeout=15, allow_redirects=True)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # ã‚¿ã‚¤ãƒˆãƒ«å–å¾—
        title = soup.find('title')
        page_title = title.get_text().strip() if title else "No Title"
        
        # ä¸è¦ãªè¦ç´ ã‚’å‰Šé™¤
        for element in soup(['script', 'style', 'nav', 'header', 'footer', 'aside']):
            element.decompose()
        
        # ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º
        text = soup.get_text()
        lines = (line.strip() for line in text.splitlines())
        chunks = (phrase.strip() for line in lines for phrase in line.split("  "))
        text = ' '.join(chunk for chunk in chunks if chunk)
        
        if len(text) > 10000:
            text = text[:10000] + "..."
        
        # è©³ç´°åˆ†æ
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel('gemini-1.5-flash')
        
        analysis_prompt = f"""
ä»¥ä¸‹ã®Webãƒšãƒ¼ã‚¸ã‚’æ¤œç´¢ã‚¯ã‚¨ãƒªã€Œ{query}ã€ã®è¦³ç‚¹ã‹ã‚‰è©³ç´°åˆ†æã—ã¦ãã ã•ã„ã€‚

ã€ãƒšãƒ¼ã‚¸æƒ…å ±ã€‘
ã‚¿ã‚¤ãƒˆãƒ«: {page_title}
URL: {url}

ã€åˆ†æè¦æ±‚ã€‘
1. è¦ç´„ï¼ˆ200æ–‡å­—ç¨‹åº¦ï¼‰
2. é‡è¦ãªãƒã‚¤ãƒ³ãƒˆï¼ˆ3-5å€‹ï¼‰
3. æ¤œç´¢ã‚¯ã‚¨ãƒªã¨ã®é–¢é€£æ€§ï¼ˆ1-5ã§è©•ä¾¡ï¼‰
4. ã“ã®ã‚µã‚¤ãƒˆã‹ã‚‰å¾—ã‚‰ã‚Œã‚‹å…·ä½“çš„ãªä¾¡å€¤
5. æ¬¡ã«èª­ã‚€ã¹ãé–¢é€£æƒ…å ±ãŒã‚ã‚Œã°ææ¡ˆ

ã€å†…å®¹ã€‘
{text[:8000]}

ã€è©³ç´°åˆ†æçµæœã€‘
"""
        
        analysis_response = model.generate_content(analysis_prompt)
        
        return {
            'success': True,
            'title': page_title,
            'url': url,
            'content_length': len(text),
            'analysis': analysis_response.text
        }
        
    except Exception as e:
        return {
            'success': False,
            'error': str(e)
        }

def main():
    st.set_page_config(
        page_title="Smart Overview & Detail Tool",
        page_icon="ğŸ“‹",
        layout="wide"
    )
    
    st.title("ğŸ“‹ Smart Overview & Detail Tool")
    st.markdown("**æ¦‚è¦ä¸€è¦§ â†’ è©³ç´°åˆ†æã®ç†æƒ³çš„ãªUI**")
    st.markdown("---")
    
    # API key check
    api_key = os.getenv("GEMINI_API_KEY")
    
    if api_key:
        st.success("âœ… Gemini API key configured")
    else:
        st.error("âŒ Gemini API key not found")
        st.stop()
    
    # Search Section
    st.subheader("ğŸ” Search & Overview")
    
    col1, col2 = st.columns([3, 1])
    
    with col1:
        query = st.text_input(
            "Search Query",
            placeholder="ä¾‹: Python æ©Ÿæ¢°å­¦ç¿’",
            help="æ¤œç´¢ã—ãŸã„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›"
        )
    
    with col2:
        auto_overview = st.checkbox("Auto Overview", value=True, help="æ¤œç´¢å¾Œã«è‡ªå‹•ã§æ¦‚è¦ã‚’ç”Ÿæˆ")
    
    if st.button("ğŸ” Search & Generate Overview", type="primary"):
        if query:
            with st.spinner("Searching and generating overviews..."):
                # Step 1: Search
                results = search_with_multiple_sources(query, 8)
                
                if results:
                    st.session_state.search_results = results
                    st.session_state.search_query = query
                    
                    # Step 2: Generate overviews
                    if auto_overview:
                        overviews = generate_quick_overview(results, query, api_key)
                        st.session_state.overviews = overviews
                    
                    st.success(f"âœ… Found {len(results)} results with overviews")
                else:
                    st.warning("No results found")
        else:
            st.warning("Please enter a search query")
    
    # Results Overview Section
    if hasattr(st.session_state, 'search_results'):
        st.markdown("---")
        st.subheader("ğŸ“‹ Results Overview")
        
        results = st.session_state.search_results
        overviews = getattr(st.session_state, 'overviews', [])
        
        # é–¢é€£åº¦ã§ã‚½ãƒ¼ãƒˆ
        if overviews:
            combined = list(zip(results, overviews))
            combined.sort(key=lambda x: x[1]['relevance'], reverse=True)
            results, overviews = zip(*combined)
        
        for i, (result, overview) in enumerate(zip(results, overviews)):
            # é–¢é€£åº¦ã«å¿œã˜ã¦è‰²ã‚’å¤‰æ›´
            relevance = overview.get('relevance', 3)
            if relevance >= 4:
                border_color = "#28a745"  # Green
            elif relevance >= 3:
                border_color = "#ffc107"  # Yellow
            else:
                border_color = "#dc3545"  # Red
            
            # ã‚«ãƒ¼ãƒ‰å½¢å¼ã§è¡¨ç¤º
            with st.container():
                st.markdown(f"""
                <div style="border: 2px solid {border_color}; border-radius: 10px; padding: 15px; margin: 10px 0;">
                    <div style="display: flex; justify-content: space-between; align-items: center;">
                        <div style="flex: 1;">
                            <h4 style="margin: 0; color: #333;">{result['title']}</h4>
                            <p style="margin: 5px 0; color: #666; font-size: 14px;">
                                <strong>æ¦‚è¦:</strong> {overview.get('overview', 'åˆ†æä¸­...')}
                            </p>
                            <p style="margin: 5px 0; color: #666; font-size: 14px;">
                                <strong>æœŸå¾…å†…å®¹:</strong> {overview.get('expected_content', 'è©³ç´°åˆ†æãŒå¿…è¦')}
                            </p>
                            <p style="margin: 5px 0; color: #888; font-size: 12px;">
                                <strong>Source:</strong> {result.get('source', 'Unknown')} | 
                                <strong>é–¢é€£åº¦:</strong> {relevance}/5
                            </p>
                        </div>
                        <div style="margin-left: 20px;">
                            <a href="{result['url']}" target="_blank" style="text-decoration: none; margin-right: 10px;">ğŸ”—</a>
                        </div>
                    </div>
                </div>
                """, unsafe_allow_html=True)
                
                # è©³ç´°åˆ†æãƒœã‚¿ãƒ³
                if st.button(f"ğŸ“„ è©³ç´°åˆ†æ", key=f"detail_{i}"):
                    with st.spinner("è©³ç´°åˆ†æä¸­..."):
                        detailed_analysis = fetch_and_analyze_detailed(
                            result['url'], 
                            st.session_state.search_query, 
                            api_key
                        )
                        
                        if detailed_analysis['success']:
                            st.markdown("---")
                            st.subheader(f"ğŸ” è©³ç´°åˆ†æ: {detailed_analysis['title']}")
                            
                            col1, col2 = st.columns([2, 1])
                            
                            with col1:
                                st.markdown(f"""
                                <div style="background-color: #f8f9fa; padding: 20px; border-radius: 10px;">
                                {detailed_analysis['analysis']}
                                </div>
                                """, unsafe_allow_html=True)
                            
                            with col2:
                                st.write(f"**URL:** {detailed_analysis['url']}")
                                st.write(f"**Content Length:** {detailed_analysis['content_length']} chars")
                                st.markdown(f"[ğŸ”— ã‚µã‚¤ãƒˆã‚’é–‹ã]({detailed_analysis['url']})")
                        else:
                            st.error(f"âŒ åˆ†æå¤±æ•—: {detailed_analysis['error']}")
    
    # Clear button
    if st.button("ğŸ—‘ï¸ Clear All"):
        for key in ['search_results', 'overviews', 'search_query']:
            if key in st.session_state:
                del st.session_state[key]
        st.rerun()

if __name__ == "__main__":
    main()