#!/usr/bin/env python3
"""
Advanced Search with Cache & Filters - SQLiteã‚­ãƒ£ãƒƒã‚·ãƒ¥ + ç’°å¢ƒãƒ•ã‚£ãƒ«ã‚¿æ©Ÿèƒ½ä»˜ãæ¤œç´¢ãƒ„ãƒ¼ãƒ«
"""

import streamlit as st
import os
import requests
from dotenv import load_dotenv
from bs4 import BeautifulSoup
import google.generativeai as genai
import time
from urllib.parse import quote_plus, urlparse, urljoin
import re
import sqlite3
import hashlib
import json
from datetime import datetime, timedelta
import platform
import sys

# Load environment variables
load_dotenv()

class SearchCache:
    """SQLiteã‚’ä½¿ç”¨ã—ãŸæ¤œç´¢çµæœã‚­ãƒ£ãƒƒã‚·ãƒ¥"""
    
    def __init__(self, db_path="gemini-url-search-tool/data/search_cache.db"):
        self.db_path = db_path
        self.init_database()
    
    def init_database(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–"""
        os.makedirs(os.path.dirname(self.db_path), exist_ok=True)
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # æ¤œç´¢çµæœã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ†ãƒ¼ãƒ–ãƒ«
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS search_cache (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                query_hash TEXT UNIQUE,
                query TEXT,
                results TEXT,
                created_at TIMESTAMP,
                accessed_at TIMESTAMP
            )
        ''')
        
        # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„åˆ†æã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ†ãƒ¼ãƒ–ãƒ«
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS content_cache (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                url_hash TEXT UNIQUE,
                url TEXT,
                title TEXT,
                analysis TEXT,
                created_at TIMESTAMP,
                accessed_at TIMESTAMP
            )
        ''')
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ç’°å¢ƒè¨­å®šãƒ†ãƒ¼ãƒ–ãƒ«
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS user_environment (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                os_name TEXT,
                python_version TEXT,
                preferences TEXT,
                created_at TIMESTAMP,
                updated_at TIMESTAMP
            )
        ''')
        
        conn.commit()
        conn.close()
    
    def get_query_hash(self, query, filters=None):
        """ã‚¯ã‚¨ãƒªã®ãƒãƒƒã‚·ãƒ¥å€¤ã‚’ç”Ÿæˆ"""
        query_data = {"query": query, "filters": filters or {}}
        return hashlib.md5(json.dumps(query_data, sort_keys=True).encode()).hexdigest()
    
    def get_url_hash(self, url):
        """URLã®ãƒãƒƒã‚·ãƒ¥å€¤ã‚’ç”Ÿæˆ"""
        return hashlib.md5(url.encode()).hexdigest()
    
    def get_cached_search(self, query, filters=None, max_age_hours=24):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸæ¤œç´¢çµæœã‚’å–å¾—"""
        query_hash = self.get_query_hash(query, filters)
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # æŒ‡å®šæ™‚é–“ä»¥å†…ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ¤œç´¢
        cutoff_time = datetime.now() - timedelta(hours=max_age_hours)
        
        cursor.execute('''
            SELECT results FROM search_cache 
            WHERE query_hash = ? AND created_at > ?
        ''', (query_hash, cutoff_time))
        
        result = cursor.fetchone()
        
        if result:
            # ã‚¢ã‚¯ã‚»ã‚¹æ™‚é–“ã‚’æ›´æ–°
            cursor.execute('''
                UPDATE search_cache SET accessed_at = ? WHERE query_hash = ?
            ''', (datetime.now(), query_hash))
            conn.commit()
            
            conn.close()
            return json.loads(result[0])
        
        conn.close()
        return None
    
    def cache_search_results(self, query, results, filters=None):
        """æ¤œç´¢çµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥"""
        query_hash = self.get_query_hash(query, filters)
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            INSERT OR REPLACE INTO search_cache 
            (query_hash, query, results, created_at, accessed_at)
            VALUES (?, ?, ?, ?, ?)
        ''', (query_hash, query, json.dumps(results), datetime.now(), datetime.now()))
        
        conn.commit()
        conn.close()
    
    def get_cached_analysis(self, url, max_age_hours=168):  # 1é€±é–“
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸã‚³ãƒ³ãƒ†ãƒ³ãƒ„åˆ†æã‚’å–å¾—"""
        url_hash = self.get_url_hash(url)
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cutoff_time = datetime.now() - timedelta(hours=max_age_hours)
        
        cursor.execute('''
            SELECT title, analysis FROM content_cache 
            WHERE url_hash = ? AND created_at > ?
        ''', (url_hash, cutoff_time))
        
        result = cursor.fetchone()
        
        if result:
            # ã‚¢ã‚¯ã‚»ã‚¹æ™‚é–“ã‚’æ›´æ–°
            cursor.execute('''
                UPDATE content_cache SET accessed_at = ? WHERE url_hash = ?
            ''', (datetime.now(), url_hash))
            conn.commit()
            
            conn.close()
            return {"title": result[0], "analysis": result[1]}
        
        conn.close()
        return None
    
    def cache_content_analysis(self, url, title, analysis):
        """ã‚³ãƒ³ãƒ†ãƒ³ãƒ„åˆ†æã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥"""
        url_hash = self.get_url_hash(url)
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            INSERT OR REPLACE INTO content_cache 
            (url_hash, url, title, analysis, created_at, accessed_at)
            VALUES (?, ?, ?, ?, ?, ?)
        ''', (url_hash, url, title, analysis, datetime.now(), datetime.now()))
        
        conn.commit()
        conn.close()
    
    def save_user_environment(self, os_name, python_version, preferences):
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ç’°å¢ƒè¨­å®šã‚’ä¿å­˜"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            INSERT OR REPLACE INTO user_environment 
            (os_name, python_version, preferences, created_at, updated_at)
            VALUES (?, ?, ?, ?, ?)
        ''', (os_name, python_version, json.dumps(preferences), datetime.now(), datetime.now()))
        
        conn.commit()
        conn.close()
    
    def get_user_environment(self):
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ç’°å¢ƒè¨­å®šã‚’å–å¾—"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT os_name, python_version, preferences FROM user_environment 
            ORDER BY updated_at DESC LIMIT 1
        ''')
        
        result = cursor.fetchone()
        conn.close()
        
        if result:
            return {
                "os_name": result[0],
                "python_version": result[1],
                "preferences": json.loads(result[2])
            }
        return None

def get_system_info():
    """ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±ã‚’è‡ªå‹•å–å¾—"""
    return {
        "os_name": platform.system(),
        "os_version": platform.version(),
        "python_version": f"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}",
        "architecture": platform.architecture()[0]
    }

def apply_environment_filters(results, user_env):
    """ç’°å¢ƒè¨­å®šã«åŸºã¥ã„ã¦æ¤œç´¢çµæœã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°"""
    if not user_env:
        return results
    
    filtered_results = []
    
    for result in results:
        score = result.get('confidence', 0.5)
        
        # OSå›ºæœ‰ã®èª¿æ•´
        if user_env.get('os_name') == 'Windows':
            if 'windows' in result['title'].lower() or 'win' in result['title'].lower():
                score += 0.2
            elif 'linux' in result['title'].lower() or 'mac' in result['title'].lower():
                score -= 0.1
        
        # Pythonãƒãƒ¼ã‚¸ãƒ§ãƒ³å›ºæœ‰ã®èª¿æ•´
        python_version = user_env.get('python_version', '')
        if python_version:
            major_version = python_version.split('.')[0]
            if f'python {major_version}' in result['title'].lower() or f'python{major_version}' in result['title'].lower():
                score += 0.2
            elif 'python 2' in result['title'].lower() and major_version == '3':
                score -= 0.3
        
        # è¨­å®šã•ã‚ŒãŸå„ªå…ˆåº¦ã«åŸºã¥ãèª¿æ•´
        preferences = user_env.get('preferences', {})
        if preferences.get('prefer_official_docs', True):
            if any(word in result['url'].lower() for word in ['docs.', 'documentation', 'official']):
                score += 0.1
        
        if preferences.get('prefer_recent_content', True):
            if any(word in result['title'].lower() for word in ['2024', '2023', 'latest', 'new']):
                score += 0.1
        
        result['confidence'] = min(1.0, max(0.0, score))
        filtered_results.append(result)
    
    # ä¿¡é ¼åº¦ã§ã‚½ãƒ¼ãƒˆ
    filtered_results.sort(key=lambda x: x['confidence'], reverse=True)
    return filtered_results

def search_with_real_urls(query, num_results=8, user_env=None):
    """å®Ÿéš›ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„URLã‚’å–å¾—ã™ã‚‹æ¤œç´¢ï¼ˆç’°å¢ƒãƒ•ã‚£ãƒ«ã‚¿ä»˜ãï¼‰"""
    results = []
    
    # ç’°å¢ƒæƒ…å ±ã‚’ã‚¯ã‚¨ãƒªã«è¿½åŠ 
    enhanced_query = query
    if user_env:
        os_name = user_env.get('os_name', '')
        python_version = user_env.get('python_version', '')
        if os_name and any(tech in query.lower() for tech in ['python', 'programming', 'development']):
            enhanced_query += f" {os_name}"
        if python_version and 'python' in query.lower():
            enhanced_query += f" python {python_version}"
    
    # Wikipediaæ¤œç´¢
    try:
        wiki_url = f"https://en.wikipedia.org/w/api.php?action=opensearch&search={quote_plus(enhanced_query)}&limit=3&format=json"
        response = requests.get(wiki_url, timeout=10)
        data = response.json()
        
        if len(data) >= 4:
            titles = data[1]
            descriptions = data[2]
            urls = data[3]
            
            for i in range(min(len(titles), 3)):
                results.append({
                    'title': f"{titles[i]} - Wikipedia",
                    'url': urls[i],
                    'description': descriptions[i] if i < len(descriptions) else "Wikipedia article",
                    'source': 'Wikipedia',
                    'confidence': 0.9
                })
    except:
        pass
    
    # GitHubæ¤œç´¢ï¼ˆæŠ€è¡“é–¢é€£ï¼‰
    try:
        tech_keywords = ['python', 'javascript', 'react', 'vue', 'angular', 'node', 'docker', 'kubernetes', 'aws', 'api', 'framework', 'library', 'vba', 'visual basic', 'excel', 'code', 'programming']
        if any(keyword in query.lower() for keyword in tech_keywords):
            github_url = f"https://api.github.com/search/repositories?q={quote_plus(enhanced_query)}&sort=stars&order=desc&per_page=2"
            response = requests.get(github_url, timeout=10)
            data = response.json()
            
            if 'items' in data:
                for repo in data['items'][:2]:
                    results.append({
                        'title': f"{repo['name']} - GitHub",
                        'url': repo['html_url'],
                        'description': repo.get('description', 'GitHub repository'),
                        'source': 'GitHub',
                        'confidence': 0.8
                    })
    except:
        pass
    
    # æ‰‹å‹•å³é¸ã‚µã‚¤ãƒˆ
    manual_sites = {
        'python': [
            {'title': 'Python.org - Official Site', 'url': 'https://www.python.org/', 'description': 'Official Python programming language website', 'confidence': 1.0},
            {'title': 'Python Tutorial', 'url': 'https://docs.python.org/3/tutorial/', 'description': 'Official Python tutorial', 'confidence': 1.0},
            {'title': 'Real Python', 'url': 'https://realpython.com/', 'description': 'High-quality Python tutorials', 'confidence': 0.9},
        ],
        'vba': [
            {'title': 'Microsoft VBA Documentation', 'url': 'https://docs.microsoft.com/en-us/office/vba/', 'description': 'Official Microsoft VBA documentation', 'confidence': 1.0},
            {'title': 'Excel VBA Tutorial', 'url': 'https://www.excel-easy.com/vba.html', 'description': 'Excel VBA tutorial and examples', 'confidence': 0.9},
        ],
    }
    
    query_lower = query.lower()
    for keyword, sites in manual_sites.items():
        if keyword in query_lower:
            for site in sites:
                site['source'] = 'Curated'
                results.append(site)
    
    # ç’°å¢ƒãƒ•ã‚£ãƒ«ã‚¿ã‚’é©ç”¨
    if user_env:
        results = apply_environment_filters(results, user_env)
    
    return results[:num_results]

def fetch_and_analyze_content_cached(url, query, api_key, cache):
    """ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ©Ÿèƒ½ä»˜ãã‚³ãƒ³ãƒ†ãƒ³ãƒ„åˆ†æ"""
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å–å¾—ã‚’è©¦è¡Œ
    cached_analysis = cache.get_cached_analysis(url)
    if cached_analysis:
        st.info("ğŸ“¦ Using cached analysis")
        return {
            'success': True,
            'title': cached_analysis['title'],
            'url': url,
            'analysis': cached_analysis['analysis'],
            'from_cache': True
        }
    
    # æ–°è¦åˆ†æ
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        
        response = requests.get(url, headers=headers, timeout=15, allow_redirects=True)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # ã‚¿ã‚¤ãƒˆãƒ«å–å¾—
        title = soup.find('title')
        page_title = title.get_text().strip() if title else "No Title"
        
        # ä¸è¦ãªè¦ç´ ã‚’å‰Šé™¤
        for element in soup(['script', 'style', 'nav', 'header', 'footer', 'aside']):
            element.decompose()
        
        # ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º
        text = soup.get_text()
        lines = (line.strip() for line in text.splitlines())
        chunks = (phrase.strip() for line in lines for phrase in line.split("  "))
        text = ' '.join(chunk for chunk in chunks if chunk)
        
        if len(text) > 8000:
            text = text[:8000] + "..."
        
        # Geminiåˆ†æ
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel('gemini-1.5-flash')
        
        analysis_prompt = f"""
ä»¥ä¸‹ã®Webãƒšãƒ¼ã‚¸ã‚’æ¤œç´¢ã‚¯ã‚¨ãƒªã€Œ{query}ã€ã®è¦³ç‚¹ã‹ã‚‰åˆ†æã—ã¦ãã ã•ã„ã€‚

ã€ãƒšãƒ¼ã‚¸æƒ…å ±ã€‘
ã‚¿ã‚¤ãƒˆãƒ«: {page_title}
URL: {url}

ã€åˆ†æè¦æ±‚ã€‘
1. è¦ç´„ï¼ˆ200æ–‡å­—ç¨‹åº¦ï¼‰
2. é‡è¦ãªãƒã‚¤ãƒ³ãƒˆï¼ˆ3-5å€‹ï¼‰
3. æ¤œç´¢ã‚¯ã‚¨ãƒªã¨ã®é–¢é€£æ€§ï¼ˆ1-5ã§è©•ä¾¡ï¼‰
4. ã“ã®ãƒšãƒ¼ã‚¸ã‹ã‚‰å¾—ã‚‰ã‚Œã‚‹å…·ä½“çš„ãªä¾¡å€¤

ã€å†…å®¹ã€‘
{text[:6000]}

ã€åˆ†æçµæœã€‘
"""
        
        analysis_response = model.generate_content(analysis_prompt)
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
        cache.cache_content_analysis(url, page_title, analysis_response.text)
        
        return {
            'success': True,
            'title': page_title,
            'url': url,
            'analysis': analysis_response.text,
            'from_cache': False
        }
        
    except Exception as e:
        return {
            'success': False,
            'error': str(e)
        }

def main():
    st.set_page_config(
        page_title="Advanced Search with Cache & Filters",
        page_icon="ğŸš€",
        layout="wide"
    )
    
    st.title("ğŸš€ Advanced Search with Cache & Filters")
    st.markdown("**SQLiteã‚­ãƒ£ãƒƒã‚·ãƒ¥ + ç’°å¢ƒãƒ•ã‚£ãƒ«ã‚¿æ©Ÿèƒ½ä»˜ãæ¤œç´¢ãƒ„ãƒ¼ãƒ«**")
    st.markdown("---")
    
    # API key check
    api_key = os.getenv("GEMINI_API_KEY")
    
    if api_key:
        st.success("âœ… Gemini API key configured")
    else:
        st.error("âŒ Gemini API key not found")
        st.stop()
    
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥åˆæœŸåŒ–
    cache = SearchCache()
    
    # ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±å–å¾—
    system_info = get_system_info()
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼šç’°å¢ƒè¨­å®š
    with st.sidebar:
        st.subheader("ğŸ”§ Environment Settings")
        
        # ç¾åœ¨ã®ç’°å¢ƒæƒ…å ±è¡¨ç¤º
        st.write("**Current System:**")
        st.write(f"OS: {system_info['os_name']} {system_info['os_version']}")
        st.write(f"Python: {system_info['python_version']}")
        st.write(f"Architecture: {system_info['architecture']}")
        
        st.markdown("---")
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼è¨­å®š
        st.write("**Search Preferences:**")
        prefer_official = st.checkbox("Prefer Official Documentation", value=True)
        prefer_recent = st.checkbox("Prefer Recent Content", value=True)
        prefer_os_specific = st.checkbox("Prefer OS-Specific Results", value=True)
        
        # ç’°å¢ƒè¨­å®šã‚’ä¿å­˜
        user_preferences = {
            "prefer_official_docs": prefer_official,
            "prefer_recent_content": prefer_recent,
            "prefer_os_specific": prefer_os_specific
        }
        
        if st.button("ğŸ’¾ Save Environment Settings"):
            cache.save_user_environment(
                system_info['os_name'],
                system_info['python_version'],
                user_preferences
            )
            st.success("Settings saved!")
    
    # ãƒ¡ã‚¤ãƒ³æ¤œç´¢ã‚¨ãƒªã‚¢
    st.subheader("ğŸ” Smart Search with Environment Filters")
    
    col1, col2 = st.columns([3, 1])
    
    with col1:
        query = st.text_input(
            "Search Query",
            placeholder="ä¾‹: Python å­¦ç¿’",
            help="æ¤œç´¢ã—ãŸã„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›"
        )
    
    with col2:
        use_cache = st.checkbox("Use Cache", value=True, help="ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ä½¿ç”¨ã—ã¦é«˜é€ŸåŒ–")
    
    if st.button("ğŸš€ Smart Search", type="primary"):
        if query:
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ç’°å¢ƒè¨­å®šã‚’å–å¾—
            user_env = cache.get_user_environment()
            if not user_env:
                user_env = {
                    "os_name": system_info['os_name'],
                    "python_version": system_info['python_version'],
                    "preferences": user_preferences
                }
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰æ¤œç´¢çµæœã‚’å–å¾—
            cached_results = None
            if use_cache:
                cached_results = cache.get_cached_search(query, user_env['preferences'])
            
            if cached_results:
                st.info("ğŸ“¦ Using cached search results")
                results = cached_results
            else:
                with st.spinner("Searching with environment filters..."):
                    results = search_with_real_urls(query, 8, user_env)
                    
                    if use_cache and results:
                        cache.cache_search_results(query, results, user_env['preferences'])
            
            if results:
                st.session_state.search_results = results
                st.session_state.search_query = query
                st.success(f"âœ… Found {len(results)} results (filtered for your environment)")
            else:
                st.warning("No results found")
        else:
            st.warning("Please enter a search query")
    
    # Results Display
    if hasattr(st.session_state, 'search_results'):
        st.markdown("---")
        st.subheader("ğŸ¯ Environment-Filtered Results")
        
        results = st.session_state.search_results
        
        for i, result in enumerate(results, 1):
            confidence = result.get('confidence', 0.5)
            if confidence >= 0.8:
                border_color = "#28a745"
            elif confidence >= 0.6:
                border_color = "#ffc107"
            else:
                border_color = "#dc3545"
            
            with st.container():
                st.markdown(f"""
                <div style="border: 2px solid {border_color}; border-radius: 10px; padding: 15px; margin: 10px 0;">
                    <div style="display: flex; justify-content: space-between; align-items: center;">
                        <div style="flex: 1;">
                            <h4 style="margin: 0; color: #333;">{result['title']}</h4>
                            <p style="margin: 5px 0; color: #666; font-size: 14px;">
                                <strong>URL:</strong> {result['url']}
                            </p>
                            <p style="margin: 5px 0; color: #666; font-size: 14px;">
                                <strong>Description:</strong> {result['description']}
                            </p>
                            <p style="margin: 5px 0; color: #888; font-size: 12px;">
                                <strong>Source:</strong> {result.get('source', 'Unknown')} | 
                                <strong>Relevance:</strong> {confidence:.1f}/1.0
                            </p>
                        </div>
                        <div style="margin-left: 20px;">
                            <a href="{result['url']}" target="_blank" style="text-decoration: none; margin-right: 10px;">ğŸ”—</a>
                        </div>
                    </div>
                </div>
                """, unsafe_allow_html=True)
                
                # è©³ç´°åˆ†æãƒœã‚¿ãƒ³
                if st.button(f"ğŸ“„ Analyze Content", key=f"analyze_{i}"):
                    with st.spinner("Analyzing content (checking cache first)..."):
                        analysis = fetch_and_analyze_content_cached(
                            result['url'], 
                            st.session_state.search_query, 
                            api_key,
                            cache
                        )
                        
                        if analysis['success']:
                            st.markdown("---")
                            cache_indicator = "ğŸ“¦ (Cached)" if analysis.get('from_cache') else "ğŸ†• (Fresh)"
                            st.subheader(f"ğŸ” Content Analysis {cache_indicator}: {analysis['title']}")
                            
                            st.markdown(f"""
                            <div style="background-color: #f8f9fa; padding: 20px; border-radius: 10px;">
                            {analysis['analysis']}
                            </div>
                            """, unsafe_allow_html=True)
                        else:
                            st.error(f"âŒ Analysis failed: {analysis['error']}")
    
    # Cache Management
    st.markdown("---")
    with st.expander("ğŸ—„ï¸ Cache Management"):
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("ğŸ“Š Cache Stats"):
                conn = sqlite3.connect(cache.db_path)
                cursor = conn.cursor()
                
                cursor.execute("SELECT COUNT(*) FROM search_cache")
                search_count = cursor.fetchone()[0]
                
                cursor.execute("SELECT COUNT(*) FROM content_cache")
                content_count = cursor.fetchone()[0]
                
                conn.close()
                
                st.write(f"Search Cache: {search_count} entries")
                st.write(f"Content Cache: {content_count} entries")
        
        with col2:
            if st.button("ğŸ§¹ Clear Old Cache"):
                conn = sqlite3.connect(cache.db_path)
                cursor = conn.cursor()
                
                # 1é€±é–“ä»¥ä¸Šå¤ã„ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’å‰Šé™¤
                cutoff_time = datetime.now() - timedelta(days=7)
                cursor.execute("DELETE FROM search_cache WHERE created_at < ?", (cutoff_time,))
                cursor.execute("DELETE FROM content_cache WHERE created_at < ?", (cutoff_time,))
                
                conn.commit()
                conn.close()
                
                st.success("Old cache cleared!")
        
        with col3:
            if st.button("ğŸ—‘ï¸ Clear All Cache"):
                conn = sqlite3.connect(cache.db_path)
                cursor = conn.cursor()
                
                cursor.execute("DELETE FROM search_cache")
                cursor.execute("DELETE FROM content_cache")
                
                conn.commit()
                conn.close()
                
                st.success("All cache cleared!")

if __name__ == "__main__":
    main()