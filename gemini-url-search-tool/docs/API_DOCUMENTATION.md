# API ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

## æ¦‚è¦

Gemini URL Search Tool ã®ä¸»è¦APIã‚¯ãƒ©ã‚¹ã¨ãƒ¡ã‚½ãƒƒãƒ‰ã®è©³ç´°ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã§ã™ã€‚

## ã‚³ã‚¢API

### GeminiClient

Gemini APIã¨ã®é€šä¿¡ã‚’æ‹…å½“ã™ã‚‹ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚¯ãƒ©ã‚¹ã€‚

#### åˆæœŸåŒ–

```python
from src.core.gemini_client import GeminiClient

client = GeminiClient(
    api_key="your_api_key",
    models=["gemini-2.0-flash-exp", "gemini-1.5-flash"],
    max_retries=3,
    timeout=30
)
```

#### ãƒ¡ã‚½ãƒƒãƒ‰

##### `search_urls(query: str, search_type: SearchType) -> List[SearchResult]`

æŒ‡å®šã•ã‚ŒãŸã‚¯ã‚¨ãƒªã§URLæ¤œç´¢ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:**
- `query` (str): æ¤œç´¢ã‚¯ã‚¨ãƒª
- `search_type` (SearchType): æ¤œç´¢ã‚¿ã‚¤ãƒ—ï¼ˆGENERAL ã¾ãŸã¯ COMPONENTï¼‰

**æˆ»ã‚Šå€¤:**
- `List[SearchResult]`: æ¤œç´¢çµæœã®ãƒªã‚¹ãƒˆ

**ä¾‹:**
```python
from src.models.data_models import SearchType

# ä¸€èˆ¬æ¤œç´¢
results = await client.search_urls("Python tutorial", SearchType.GENERAL)

# éƒ¨å“æ¤œç´¢
results = await client.search_urls("Arduino UNO R3", SearchType.COMPONENT)
```

##### `analyze_content(url: str) -> ContentAnalysis`

æŒ‡å®šã•ã‚ŒãŸURLã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’åˆ†æã—ã¾ã™ã€‚

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:**
- `url` (str): åˆ†æå¯¾è±¡ã®URL

**æˆ»ã‚Šå€¤:**
- `ContentAnalysis`: ã‚³ãƒ³ãƒ†ãƒ³ãƒ„åˆ†æçµæœ

**ä¾‹:**
```python
analysis = await client.analyze_content("https://example.com")
print(analysis.summary)
```

##### `generate_summary(content: str, focus_areas: List[str] = None) -> str`

ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®è¦ç´„ã‚’ç”Ÿæˆã—ã¾ã™ã€‚

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:**
- `content` (str): è¦ç´„å¯¾è±¡ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
- `focus_areas` (List[str], optional): é‡ç‚¹çš„ã«è¦ç´„ã™ã‚‹é ˜åŸŸ

**æˆ»ã‚Šå€¤:**
- `str`: ç”Ÿæˆã•ã‚ŒãŸè¦ç´„

**ä¾‹:**
```python
summary = await client.generate_summary(
    content="é•·ã„ãƒ†ã‚­ã‚¹ãƒˆã‚³ãƒ³ãƒ†ãƒ³ãƒ„...",
    focus_areas=["æŠ€è¡“ä»•æ§˜", "ä¾¡æ ¼æƒ…å ±"]
)
```

### SearchService

æ¤œç´¢æ©Ÿèƒ½ã‚’æä¾›ã™ã‚‹ã‚µãƒ¼ãƒ“ã‚¹ã‚¯ãƒ©ã‚¹ã€‚

#### åˆæœŸåŒ–

```python
from src.core.search_service import SearchService
from src.models.repository import SearchRepository

repository = SearchRepository("data/search_results.db")
search_service = SearchService(
    gemini_client=client,
    search_repository=repository,
    max_results=10
)
```

#### ãƒ¡ã‚½ãƒƒãƒ‰

##### `search_general(keywords: str) -> SearchResults`

ä¸€èˆ¬çš„ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:**
- `keywords` (str): æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰

**æˆ»ã‚Šå€¤:**
- `SearchResults`: æ¤œç´¢çµæœã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ

**ä¾‹:**
```python
results = await search_service.search_general("æ©Ÿæ¢°å­¦ç¿’ Python")
for result in results.results:
    print(f"{result.title}: {result.url}")
```

##### `search_component_specs(manufacturer: str, part_number: str) -> SearchResults`

éƒ¨å“ä»•æ§˜æ¤œç´¢ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:**
- `manufacturer` (str): ãƒ¡ãƒ¼ã‚«ãƒ¼å
- `part_number` (str): å“ç•ª

**æˆ»ã‚Šå€¤:**
- `SearchResults`: æ¤œç´¢çµæœã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ

**ä¾‹:**
```python
results = await search_service.search_component_specs("Arduino", "UNO R3")
```

##### `get_search_history(filters: SearchFilters = None) -> List[SearchRecord]`

æ¤œç´¢å±¥æ­´ã‚’å–å¾—ã—ã¾ã™ã€‚

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:**
- `filters` (SearchFilters, optional): ãƒ•ã‚£ãƒ«ã‚¿æ¡ä»¶

**æˆ»ã‚Šå€¤:**
- `List[SearchRecord]`: æ¤œç´¢å±¥æ­´ã®ãƒªã‚¹ãƒˆ

**ä¾‹:**
```python
from src.models.data_models import SearchFilters
from datetime import datetime, timedelta

# éå»7æ—¥é–“ã®æ¤œç´¢å±¥æ­´
filters = SearchFilters(
    start_date=datetime.now() - timedelta(days=7),
    search_type=SearchType.GENERAL
)
history = search_service.get_search_history(filters)
```

### ContentService

ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å‡¦ç†æ©Ÿèƒ½ã‚’æä¾›ã™ã‚‹ã‚µãƒ¼ãƒ“ã‚¹ã‚¯ãƒ©ã‚¹ã€‚

#### åˆæœŸåŒ–

```python
from src.core.content_service import ContentService

content_service = ContentService(gemini_client=client)
```

#### ãƒ¡ã‚½ãƒƒãƒ‰

##### `analyze_url(url: str) -> ContentAnalysis`

URLã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å–å¾—ãƒ»åˆ†æã—ã¾ã™ã€‚

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:**
- `url` (str): åˆ†æå¯¾è±¡ã®URL

**æˆ»ã‚Šå€¤:**
- `ContentAnalysis`: åˆ†æçµæœ

**ä¾‹:**
```python
analysis = await content_service.analyze_url("https://example.com")
print(f"ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚¿ã‚¤ãƒ—: {analysis.content_type}")
print(f"è¦ç´„: {analysis.summary}")
print(f"ä¸»è¦ãƒã‚¤ãƒ³ãƒˆ: {analysis.key_points}")
```

##### `extract_technical_specs(content: str) -> Dict[str, Any]`

æŠ€è¡“ä»•æ§˜ã‚’æŠ½å‡ºã—ã¾ã™ã€‚

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:**
- `content` (str): å¯¾è±¡ã‚³ãƒ³ãƒ†ãƒ³ãƒ„

**æˆ»ã‚Šå€¤:**
- `Dict[str, Any]`: æŠ½å‡ºã•ã‚ŒãŸæŠ€è¡“ä»•æ§˜

**ä¾‹:**
```python
specs = await content_service.extract_technical_specs(content)
print(f"ä»•æ§˜: {specs}")
```

### StorageService

ãƒ‡ãƒ¼ã‚¿ä¿å­˜ãƒ»ç®¡ç†æ©Ÿèƒ½ã‚’æä¾›ã™ã‚‹ã‚µãƒ¼ãƒ“ã‚¹ã‚¯ãƒ©ã‚¹ã€‚

#### åˆæœŸåŒ–

```python
from src.core.storage_service import StorageService

storage_service = StorageService(db_path="data/search_results.db")
```

#### ãƒ¡ã‚½ãƒƒãƒ‰

##### `save_search_result(search_record: SearchRecord) -> int`

æ¤œç´¢çµæœã‚’ä¿å­˜ã—ã¾ã™ã€‚

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:**
- `search_record` (SearchRecord): ä¿å­˜ã™ã‚‹æ¤œç´¢è¨˜éŒ²

**æˆ»ã‚Šå€¤:**
- `int`: ä¿å­˜ã•ã‚ŒãŸãƒ¬ã‚³ãƒ¼ãƒ‰ã®ID

##### `save_content_analysis(analysis: ContentAnalysis) -> int`

ã‚³ãƒ³ãƒ†ãƒ³ãƒ„åˆ†æçµæœã‚’ä¿å­˜ã—ã¾ã™ã€‚

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:**
- `analysis` (ContentAnalysis): ä¿å­˜ã™ã‚‹åˆ†æçµæœ

**æˆ»ã‚Šå€¤:**
- `int`: ä¿å­˜ã•ã‚ŒãŸãƒ¬ã‚³ãƒ¼ãƒ‰ã®ID

##### `get_saved_content(content_id: int) -> ContentAnalysis`

ä¿å­˜ã•ã‚ŒãŸã‚³ãƒ³ãƒ†ãƒ³ãƒ„åˆ†æã‚’å–å¾—ã—ã¾ã™ã€‚

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:**
- `content_id` (int): ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ID

**æˆ»ã‚Šå€¤:**
- `ContentAnalysis`: åˆ†æçµæœ

### EvaluationService

è©•ä¾¡ãƒ»åˆ†ææ©Ÿèƒ½ã‚’æä¾›ã™ã‚‹ã‚µãƒ¼ãƒ“ã‚¹ã‚¯ãƒ©ã‚¹ã€‚

#### åˆæœŸåŒ–

```python
from src.evaluation.evaluation_service import EvaluationService

evaluation_service = EvaluationService(storage_service=storage_service)
```

#### ãƒ¡ã‚½ãƒƒãƒ‰

##### `calculate_search_metrics(time_range: DateRange) -> SearchMetrics`

æ¤œç´¢ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¨ˆç®—ã—ã¾ã™ã€‚

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:**
- `time_range` (DateRange): è¨ˆç®—å¯¾è±¡ã®æœŸé–“

**æˆ»ã‚Šå€¤:**
- `SearchMetrics`: è¨ˆç®—ã•ã‚ŒãŸãƒ¡ãƒˆãƒªã‚¯ã‚¹

##### `track_user_interaction(interaction: UserInteraction) -> None`

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã‚’è¨˜éŒ²ã—ã¾ã™ã€‚

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:**
- `interaction` (UserInteraction): ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³æƒ…å ±

## ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«

### SearchResult

æ¤œç´¢çµæœã‚’è¡¨ã™ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹ã€‚

```python
@dataclass
class SearchResult:
    url: str                    # æ¤œç´¢çµæœã®URL
    title: str                  # ãƒšãƒ¼ã‚¸ã‚¿ã‚¤ãƒˆãƒ«
    description: str            # èª¬æ˜æ–‡
    rank: int                   # ãƒ©ãƒ³ã‚­ãƒ³ã‚°é †ä½
    is_official: bool = False   # å…¬å¼ã‚½ãƒ¼ã‚¹ã‹ã©ã†ã‹
    confidence_score: float = 0.0  # ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢
    source_type: str = "web"    # ã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—
    language: str = "ja"        # è¨€èª
    created_at: datetime = None # ä½œæˆæ—¥æ™‚
```

### ContentAnalysis

ã‚³ãƒ³ãƒ†ãƒ³ãƒ„åˆ†æçµæœã‚’è¡¨ã™ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹ã€‚

```python
@dataclass
class ContentAnalysis:
    url: str                    # åˆ†æå¯¾è±¡URL
    content_type: str           # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚¿ã‚¤ãƒ—
    summary: str                # è¦ç´„æ–‡
    key_points: List[str]       # ä¸»è¦ãƒã‚¤ãƒ³ãƒˆ
    technical_specs: Dict[str, Any]  # æŠ€è¡“ä»•æ§˜
    extraction_time: float      # å‡¦ç†æ™‚é–“
    content_size: int           # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚µã‚¤ã‚º
    language: str = "ja"        # è¨€èª
    confidence_score: float = 0.0  # ä¿¡é ¼åº¦
    created_at: datetime = None # ä½œæˆæ—¥æ™‚
```

### SearchRecord

æ¤œç´¢è¨˜éŒ²ã‚’è¡¨ã™ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹ã€‚

```python
@dataclass
class SearchRecord:
    id: Optional[int] = None    # ãƒ¬ã‚³ãƒ¼ãƒ‰ID
    query: str = ""             # æ¤œç´¢ã‚¯ã‚¨ãƒª
    search_type: SearchType = SearchType.GENERAL  # æ¤œç´¢ã‚¿ã‚¤ãƒ—
    manufacturer: Optional[str] = None  # ãƒ¡ãƒ¼ã‚«ãƒ¼åï¼ˆéƒ¨å“æ¤œç´¢æ™‚ï¼‰
    part_number: Optional[str] = None   # å“ç•ªï¼ˆéƒ¨å“æ¤œç´¢æ™‚ï¼‰
    results_count: int = 0      # çµæœæ•°
    search_time: float = 0.0    # æ¤œç´¢æ™‚é–“
    created_at: datetime = None # ä½œæˆæ—¥æ™‚
    results: List[SearchResult] = field(default_factory=list)  # æ¤œç´¢çµæœ
```

### SearchMetrics

æ¤œç´¢ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¡¨ã™ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹ã€‚

```python
@dataclass
class SearchMetrics:
    total_searches: int = 0         # ç·æ¤œç´¢æ•°
    avg_search_time: float = 0.0    # å¹³å‡æ¤œç´¢æ™‚é–“
    success_rate: float = 0.0       # æˆåŠŸç‡
    avg_usefulness_rating: float = 0.0  # å¹³å‡æœ‰ç”¨æ€§è©•ä¾¡
    time_saved_total: int = 0       # ç·æ™‚é–“ç¯€ç´„ï¼ˆåˆ†ï¼‰
    most_common_queries: List[str] = field(default_factory=list)  # é »å‡ºã‚¯ã‚¨ãƒª
    improvement_suggestions: List[str] = field(default_factory=list)  # æ”¹å–„ææ¡ˆ
```

## ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

### ã‚«ã‚¹ã‚¿ãƒ ä¾‹å¤–

#### SearchError

æ¤œç´¢é–¢é€£ã®ã‚¨ãƒ©ãƒ¼ã€‚

```python
from src.utils.error_handler import SearchError

try:
    results = await search_service.search_general("query")
except SearchError as e:
    print(f"æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e.message}")
    print(f"ã‚¨ãƒ©ãƒ¼ã‚³ãƒ¼ãƒ‰: {e.error_code}")
```

#### ContentFetchError

ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å–å¾—é–¢é€£ã®ã‚¨ãƒ©ãƒ¼ã€‚

```python
from src.utils.error_handler import ContentFetchError

try:
    analysis = await content_service.analyze_url("https://example.com")
except ContentFetchError as e:
    print(f"ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å–å¾—ã‚¨ãƒ©ãƒ¼: {e.message}")
    print(f"URL: {e.url}")
```

#### ValidationError

ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³é–¢é€£ã®ã‚¨ãƒ©ãƒ¼ã€‚

```python
from src.utils.error_handler import ValidationError

try:
    # ç„¡åŠ¹ãªURLã§ã®æ¤œç´¢
    results = await search_service.search_general("")
except ValidationError as e:
    print(f"ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼: {e.message}")
    print(f"ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰: {e.field}")
```

## è¨­å®šã‚ªãƒ—ã‚·ãƒ§ãƒ³

### config.json è¨­å®šé …ç›®

```json
{
  "app": {
    "name": "ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å",
    "version": "ãƒãƒ¼ã‚¸ãƒ§ãƒ³",
    "debug": false
  },
  "gemini": {
    "models": ["ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã®ãƒªã‚¹ãƒˆ"],
    "max_retries": 3,
    "timeout": 30,
    "rate_limit_delay": 1.0
  },
  "search": {
    "max_results": 10,
    "default_search_type": "general",
    "enable_caching": true,
    "cache_duration_hours": 24
  },
  "content": {
    "max_content_size": 1048576,
    "chunk_size": 4096,
    "summary_max_length": 1000,
    "extraction_timeout": 60
  },
  "database": {
    "path": "data/search_results.db",
    "backup_enabled": true,
    "cleanup_days": 30
  },
  "ui": {
    "page_title": "ãƒšãƒ¼ã‚¸ã‚¿ã‚¤ãƒˆãƒ«",
    "page_icon": "ğŸ”",
    "layout": "wide",
    "sidebar_state": "expanded"
  },
  "logging": {
    "level": "INFO",
    "file": "logs/app.log",
    "max_size_mb": 10,
    "backup_count": 5
  }
}
```

## ä½¿ç”¨ä¾‹

### å®Œå…¨ãªæ¤œç´¢ãƒ•ãƒ­ãƒ¼

```python
import asyncio
from src.core.gemini_client import GeminiClient
from src.core.search_service import SearchService
from src.core.content_service import ContentService
from src.models.repository import SearchRepository

async def complete_search_flow():
    # åˆæœŸåŒ–
    client = GeminiClient(api_key="your_api_key")
    repository = SearchRepository("data/search_results.db")
    search_service = SearchService(client, repository)
    content_service = ContentService(client)
    
    # æ¤œç´¢å®Ÿè¡Œ
    search_results = await search_service.search_general("Python æ©Ÿæ¢°å­¦ç¿’")
    
    # æœ€åˆã®çµæœã‚’åˆ†æ
    if search_results.results:
        first_result = search_results.results[0]
        analysis = await content_service.analyze_url(first_result.url)
        
        print(f"ã‚¿ã‚¤ãƒˆãƒ«: {first_result.title}")
        print(f"URL: {first_result.url}")
        print(f"è¦ç´„: {analysis.summary}")
        print(f"ä¸»è¦ãƒã‚¤ãƒ³ãƒˆ: {analysis.key_points}")

# å®Ÿè¡Œ
asyncio.run(complete_search_flow())
```

### ãƒãƒƒãƒå‡¦ç†

```python
async def batch_analysis():
    client = GeminiClient(api_key="your_api_key")
    content_service = ContentService(client)
    
    urls = [
        "https://example1.com",
        "https://example2.com",
        "https://example3.com"
    ]
    
    # ä¸¦åˆ—å‡¦ç†ã§è¤‡æ•°URLã‚’åˆ†æ
    tasks = [content_service.analyze_url(url) for url in urls]
    analyses = await asyncio.gather(*tasks, return_exceptions=True)
    
    for i, analysis in enumerate(analyses):
        if isinstance(analysis, Exception):
            print(f"URL {urls[i]} ã®åˆ†æã«å¤±æ•—: {analysis}")
        else:
            print(f"URL {urls[i]} ã®è¦ç´„: {analysis.summary}")

asyncio.run(batch_analysis())
```

### ã‚«ã‚¹ã‚¿ãƒ è©•ä¾¡

```python
from src.evaluation.evaluation_service import EvaluationService
from src.models.data_models import UserInteraction, InteractionType

async def custom_evaluation():
    storage_service = StorageService("data/search_results.db")
    evaluation_service = EvaluationService(storage_service)
    
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã®è¨˜éŒ²
    interaction = UserInteraction(
        content_id=1,
        interaction_type=InteractionType.RATING,
        rating=5,
        feedback="éå¸¸ã«æœ‰ç”¨ãªæƒ…å ±ã§ã—ãŸ",
        time_saved_minutes=30
    )
    
    evaluation_service.track_user_interaction(interaction)
    
    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—
    from datetime import datetime, timedelta
    from src.models.data_models import DateRange
    
    date_range = DateRange(
        start_date=datetime.now() - timedelta(days=30),
        end_date=datetime.now()
    )
    
    metrics = evaluation_service.calculate_search_metrics(date_range)
    print(f"ç·æ¤œç´¢æ•°: {metrics.total_searches}")
    print(f"æˆåŠŸç‡: {metrics.success_rate:.2%}")
    print(f"å¹³å‡è©•ä¾¡: {metrics.avg_usefulness_rating:.1f}/5.0")

asyncio.run(custom_evaluation())
```